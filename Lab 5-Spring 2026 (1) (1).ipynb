{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "###### Follow the instructions given in comments prefixed with ## and write your code below that.\n",
    "###### Also fill the partial code in given blanks. \n",
    "###### Don't make any changes to the rest part of the codes\n",
    "\n",
    "### Answer the questions given at the end of this notebook within your report.\n",
    "\n",
    "### You would need to submit your GitHub repository link. Refer to the PDF document for the instructions and details.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import cv2\n",
    "import cv2\n",
    "## import numpy\n",
    "import numpy as np\n",
    "## import matplotlib pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "## import KMeans cluster from sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "## import distance from scipy.spatial\n",
    "from scipy.spatial import distance\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the image plaksha_Faculty.jpg\n",
    "img=cv2.imread(r\"C:\\Users\\keert\\Downloads\\Plaksha_Faculty.jpg\")\n",
    "  \n",
    "## Convert the image to grayscale\n",
    "gray_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "# Loading the required haar-cascade xml classifier file\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "  \n",
    "# Applying the face detection method on the grayscale image. \n",
    "## Change the parameters for better detection of faces in your case.\n",
    "faces_rect = face_cascade.detectMultiScale(gray_img, 1.05, 4, minSize=(25,25), maxSize=(50,50))\n",
    " \n",
    "# Define the text and font parameters\n",
    "text = \"Face\" ## The text you want to write\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX  ## Font type\n",
    "font_scale = 1  ## Font scale factor\n",
    "font_color = (0,0,255)  ## Text color in BGR format (here, it's red)\n",
    "font_thickness = 1 ## Thickness of the text\n",
    "\n",
    "  \n",
    "# Iterating through rectangles of detected faces\n",
    "for (x, y, w, h) in faces_rect:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "    # Use cv2.putText to add the text to the image, Use text, font, font_scale, font_color, font_thickness here\n",
    "    cv2.putText(img, text, (x,y),font,font_scale,font_color,font_thickness)\n",
    "    \n",
    "## Display the image and window title should be \"Total number of face detected are #\"  \n",
    "cv2.imshow(f\"Total no.of faces detected are {len(faces_rect)}\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "# Extract face region features (Hue and Saturation)\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) ## call the img and convert it from BGR to HSV and store in img_hsv\n",
    "hue_saturation = []\n",
    "face_images = []  # To store detected face images\n",
    "\n",
    "for (x, y, w, h) in faces_rect:\n",
    "    face = img_hsv[y:y + h, x:x + w]\n",
    "    hue = np.mean(face[:, :, 0])\n",
    "    saturation = np.mean(face[:, :, 1])\n",
    "    hue_saturation.append((hue, saturation))\n",
    "    face_images.append(face)\n",
    "\n",
    "hue_saturation = np.array(hue_saturation)\n",
    "\n",
    "## Perform k-Means clustering on hue_saturation and store in kmeans\n",
    "kmeans =KMeans(n_clusters=2,random_state=10).fit(hue_saturation)\n",
    "centroids = kmeans.cluster_centers_\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot the clustered faces with custom markers\n",
    "for i, (x,y,w,h ) in enumerate(faces_rect):\n",
    "    im = OffsetImage(cv2.cvtColor(cv2.resize(face_images[i], (20, 20)), cv2.COLOR_HSV2RGB))\n",
    "    ab = AnnotationBbox(im, (hue_saturation[i, 0], hue_saturation[i, 1]), frameon=False, pad=0)\n",
    "    ax.add_artist(ab)\n",
    "    plt.plot(hue_saturation[i, 0], hue_saturation[i, 1])\n",
    "    \n",
    "\n",
    "## Put x label\n",
    "plt.xlabel(\"Hue\")\n",
    "## Put y label\n",
    "plt.ylabel(\"Saturation\")\n",
    "## Put title\n",
    "plt.title(\"Feature based clustering into two classes using k-Means\")\n",
    "## Put grid\n",
    "plt.grid(True)\n",
    "## show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store legend labels\n",
    "legend_labels = []\n",
    "\n",
    "# Create lists to store points for each cluster\n",
    "cluster_0_points = []\n",
    "cluster_1_points = []\n",
    "\n",
    "# Your code for scatter plot goes here\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for i, (x, y, w, h) in enumerate(faces_rect):\n",
    "    if kmeans.labels_[i] == 0:\n",
    "        cluster_0_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n",
    "    else:\n",
    "        cluster_1_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n",
    "\n",
    "\n",
    "cluster_0_points = np.array(cluster_0_points)\n",
    "# Plot points for cluster 0 in green\n",
    "plt.scatter(cluster_0_points[:,0],cluster_0_points[:,1], c=\"green\", marker=\"o\", s=100, label =\"Cluster 0\")\n",
    "\n",
    "\n",
    "cluster_1_points = np.array(cluster_1_points)\n",
    "# Plot points for cluster 1 in blue\n",
    "plt.scatter(cluster_1_points[:,0],cluster_1_points[:,1], c=\"blue\", marker=\"o\", s=100, label =\"Cluster 1\")\n",
    "\n",
    "# Calculate and plot centroids\n",
    "centroid_0 = np.mean(cluster_0_points, axis=0)\n",
    "centroid_1 = np.mean(cluster_1_points, axis=0)\n",
    "\n",
    "# Plot both the centroid for cluster 0 and cluster 1 \n",
    "plt.scatter(centroid_0[0], centroid_0[1], c=\"pink\", marker=\"X\", s=200, label=\"Centroid 0\")\n",
    "plt.scatter(centroid_1[0], centroid_1[1], c=\"yellow\", marker=\"X\", s=200, label=\"Centroid 1\")\n",
    "\n",
    "\n",
    "## Put x label\n",
    "plt.xlabel(\"Hue\")\n",
    "## Put y label\n",
    "plt.ylabel(\"Saturation\")\n",
    "## Put title\n",
    "plt.title(\"Scatter plot of k-Means clusters\") \n",
    "## Add a legend\n",
    "plt.legend()\n",
    "## Add grid\n",
    "plt.grid(True)\n",
    "## Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the class of the template image 'Dr_Shashi_Tharoor.jpg' using cv2 and store it in template_img\n",
    "template_img = cv2.imread(r\"C:\\Users\\keert\\Downloads\\Dr_Shashi_Tharoor.jpg\")\n",
    "# Detect face  in the template image after converting it to gray and store it in template_faces\n",
    "template_gray = cv2.cvtColor(template_img, cv2.COLOR_BGR2GRAY)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "template_faces = face_cascade.detectMultiScale, template_gray, scaleFactor=1.1, minNeighbors=5\n",
    "# Draw rectangles around the detected faces\n",
    "for (x, y, w, h) in template_faces:\n",
    "    cv2.rectangle(template_img, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "cv2.imshow(\"Detected faces\",template_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the template image to HSV color space and store it in template_hsv\n",
    "template_hsv = cv2.cvtColor(template_img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Extract hue and saturation features from the template image as we did it for detected faces.\n",
    "template_hsv = cv2.cvtColor(template_img, cv2.COLOR_BGR2HSV)\n",
    "template_face = template_hsv\n",
    "template_hue = np.mean(template_face[:, :, 0])\n",
    "template_saturation = np.mean(template_face[:, :, 1])\n",
    "\n",
    "# Predict the cluster label for the template image and store it in template_label\n",
    "template_label = kmeans.predict([[template_hue, template_saturation]])[0]\n",
    "\n",
    "# Create a figure and axis for visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot the clustered faces with custom markers (similar to previous code)\n",
    "for i, (x, y, w, h) in enumerate(faces_rect):\n",
    "    color = 'red' if kmeans.labels_[i] == 0 else 'blue'\n",
    "    im = OffsetImage(cv2.cvtColor(cv2.resize(face_images[i], (20, 20)), cv2.COLOR_HSV2RGB))\n",
    "    ab = AnnotationBbox(im, (hue_saturation[i, 0], hue_saturation[i, 1]), frameon=False, pad=0)\n",
    "    ax.add_artist(ab)\n",
    "    plt.plot(hue_saturation[i, 0], hue_saturation[i, 1], 'o', markersize=5, color=color)\n",
    "\n",
    "# Plot the template image in the respective cluster\n",
    "if template_label == 0:\n",
    "    color = 'red'\n",
    "else:\n",
    "    color = 'blue'\n",
    "im = OffsetImage(cv2.cvtColor(cv2.resize(template_img, (20, 20)), cv2.COLOR_BGR2RGB))\n",
    "ab = AnnotationBbox(im, (template_hue, template_saturation), frameon=False, pad=0)\n",
    "ax.add_artist(ab)\n",
    "\n",
    "## Put x label\n",
    "plt.xlabel(\"Hue\")\n",
    "## Put y label\n",
    "plt.ylabel(\"Saturation\")\n",
    "## Put title\n",
    "plt.title(\"Clsutering with template image\")\n",
    "## Add grid\n",
    "plt.grid(True)\n",
    "## show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store legend labels\n",
    "legend_labels = []\n",
    "\n",
    "# Create lists to store points for each cluster\n",
    "cluster_0_points = []\n",
    "cluster_1_points = []\n",
    "\n",
    "# Your code for scatter plot goes here\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for i, (x, y, w, h) in enumerate(faces_rect):\n",
    "    if kmeans.labels_[i] == 0:\n",
    "        cluster_0_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n",
    "    else:\n",
    "        cluster_1_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n",
    "\n",
    "# Plot points for cluster 0 in green\n",
    "cluster_0_points = np.array(cluster_0_points)\n",
    "plt.scatter(cluster_0_points[:, 0], cluster_0_points[:, 1],c=\"green\", marker=\"o\", s=100, label=\"Cluster 0\")\n",
    "\n",
    "# Plot points for cluster 1 in blue\n",
    "cluster_1_points = np.array(cluster_1_points)\n",
    "plt.scatter(cluster_1_points[:, 0], cluster_1_points[:, 1],c=\"blue\", marker=\"o\", s=100, label=\"Cluster 1\")\n",
    "\n",
    "# Calculate and plot centroids for both the clusters\n",
    "centroid_0 =np.mean(cluster_0_points,axis=0)\n",
    "centroid_1 =np.mean(cluster_1_points, axis=0)\n",
    "plt.scatter(centroid_0[0], centroid_0[1], c=\"red\", marker=\"X\", s=250, label=\"Centroid 0\")\n",
    "plt.scatter(centroid_1[0], centroid_1[1],c=\"black\", marker=\"X\", s=250, label=\"Centroid 1\")\n",
    "plt.plot(template_hue, template_saturation, marker='o', c= 'violet',markersize= 10, label=f\"Class {template_label}\")\n",
    "\n",
    "## Put x label\n",
    "plt.xlabel(\"Hue\")\n",
    "## Put y label\n",
    "plt.ylabel(\"Saturation\")\n",
    "## Put title\n",
    "plt.title(\"Scatter plot of k-Means clusters\")\n",
    "## Add a legend\n",
    "plt.legend()\n",
    "## Add grid\n",
    "plt.grid(True)\n",
    "## show the plot\n",
    "plt.show()\n",
    "                                            ## End of the lab 5 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report:\n",
    "## Answer the following questions within your report:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What are the common distance metrics used in distance-based classification algorithms? \n",
    "\n",
    "#### 2. What are some real-world applications of distance-based classification algorithms? \n",
    "\n",
    "#### 3. Explain various distance metrics. \n",
    "\n",
    "#### 4. What is the role of cross validation in model performance? \n",
    "\n",
    "#### 5. Explain variance and bias in terms of KNN? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1A : Euclidean distance\n",
    "     Mahalanobis Distance\n",
    "     Manhattan Distance\n",
    "     Chebyshev Distance\n",
    "     Minkowski Distance\n",
    "     Cosine Distance\n",
    "     Hamming Distance\n",
    "\n",
    "2A : Spam detection to classify junk/spam emials from important ones, Classifying the side effect of drugs in pharmaceuticals, Disease detection in medicine, etc\n",
    "\n",
    "3A : Euclidean distance- Represents the shortest distance between two vectors\n",
    "     Mahalanobis Distance- Represents the distance between a point P and a distribution D\n",
    "     Manhattan Distance- Distance between two points measured along axes at right angles.\n",
    "     Chebyshev Distance- It is defined on a vector space where the distance between two vectors is the greatest of their differences along any      coordinate dimension\n",
    "     Minkowski Distance- A generalized distance metric which can be modified by substituting the value of ‘p’ to calculate the distance between two points. If p = 1, Manhattan Distance, called L1 norm, If p = 2, Euclidean Distance, called L2 norm, If p = ∞, Chebychev Distance, called L∞ norm\n",
    "     Cosine Distance- Degree of angle between two vectors (called frequencies for words in documents). It is used when the magnitude does not matter but rather their orientation matters.\n",
    "     Hamming Distance- Comparing two strings (or bits), number of positions in which the two strings (or bits) are different\n",
    "\n",
    "4A : Increase accuracy, reduce bias and hemce overfitting, reduce variance,etc\n",
    "\n",
    "5A : Very low k value(1,2) may be noisy since nearby outliers may influence classification. This increases variance and hence underfitting.\n",
    "     Large k values are better but if its too big, all data points may get assigned to the larger/closer of the classes. This increases bias and hence overfitting.s. normn.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
